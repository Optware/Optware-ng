--- common/ppc/dct.c.orig	2007-02-01 20:50:54.000000000 -0800
+++ common/ppc/dct.c	2007-02-02 11:29:45.000000000 -0800
@@ -294,9 +294,9 @@
     vec_u8_t hv = vec_ld( 0, dest );                           \
     vec_u8_t lv = vec_ld( 7, dest );                           \
     vec_u8_t dstv   = vec_perm( hv, lv, (vec_u8_t)perm_ldv );  \
-    vec_s16_t idct_sh6 = vec_sra(idctv, sixv);                 \
-    vec_u16_t dst16 = vec_mergeh(zero_u8v, dstv);              \
-    vec_s16_t idstsum = vec_adds(idct_sh6, (vec_s16_t)dst16);  \
+    vec_s16_t idct_sh6 = (vec_s16_t) vec_sra(idctv, sixv);                 \
+    vec_u16_t dst16 = (vec_u16_t) vec_mergeh(zero_u8v, dstv);              \
+    vec_s16_t idstsum = (vec_s16_t) vec_adds(idct_sh6, (vec_s16_t)dst16);  \
     vec_u8_t idstsum8 = vec_packsu(zero_s16v, idstsum);        \
     /* unaligned store */                                      \
     vec_u8_t bodyv  = vec_perm( idstsum8, idstsum8, perm_stv );\
@@ -311,8 +311,8 @@
 
 void x264_add8x8_idct8_altivec( uint8_t *dst, int16_t dct[8][8] )
 {
-    vec_u16_t onev = vec_splat_s16(1);
-    vec_u16_t twov = vec_splat_s16(2);
+    vec_u16_t onev = (vec_u16_t) vec_splat_s16(1);
+    vec_u16_t twov = (vec_u16_t) vec_splat_s16(2);
 
     dct[0][0] += 32; // rounding for the >>6 at the end
 
@@ -341,7 +341,7 @@
 
     vec_u8_t perm_ldv = vec_lvsl(0, dst);
     vec_u8_t perm_stv = vec_lvsr(8, dst);
-    vec_u16_t sixv = vec_splat_s16(6);
+    vec_u16_t sixv = (vec_u16_t) vec_splat_s16(6);
     const vec_u8_t sel = (vec_u8_t) CV(0,0,0,0,0,0,0,0,-1,-1,-1,-1,-1,-1,-1,-1);
     LOAD_ZERO;
 
